from snakemake.utils import Paramspace
import numpy as np
import pandas as pd
from itertools import product
import uuid
import platform

FIPY_PATH = "/Users/guyer/Documents/research/FiPy/fipy"

include: "rules/common.smk"

SUITES = ["petsc"]
# calculate dimensions that produce six orders of magnitude in number of cells
# SIZES = (10**(np.arange(1, 6.5, 1.)/2)).round().astype(int)**2
SIZES = (10**(np.arange(1, 2.5, 1.)/2)).round().astype(int)**2
# BENCHMARKS = ["binary_phase_field", "diffusion", "nucleation"]
BENCHMARKS = ["binary_phase_field"]

# PERMUTATIONS = pd.read_json("results/permutations.json")

rule all:
    input:
        permutations="results/permutations.json",
        logs=get_all_logs

rule add_benchmark:
    input:
        expand(f"benchmark~{{solversuite}}.txt", solversuite=SUITES)

rule add_suite_benchmark:
    output:
        "benchmark~{solversuite}.txt"
    input:
        "solvers~{solversuite}.txt",
        "preconditioners~{solversuite}.txt",
        "thumbprint~{solversuite}.txt",
        tatanka_suite
    conda:
        "snakemake"
    log:
        "benchmark~{solversuite}.log"
    shell:
        "touch {output}"

rule current_version:
    input:
    output:
        "current_version.txt"
    conda:
        "snakemake"
    log:
        "current_version.log"
    shell:
        "echo (mkdir -p results/$(git rev-parse --short HEAD)/"
        "$(python -c \"import fipy; print(fipy.__version__)\")) > {output} 2> {log}"
        
rule ipynb2py:
    input:
        "codes/notebooks/{notebook}.ipynb"
    output:
        temp("codes/scripts/{notebook}.py")
    conda:
        "snakemake"
    log:
        stdout="codes/scripts/{notebook}.stdout",
        stderr="codes/scripts/{notebook}.stderr"
    shell:
        "jupyter nbconvert {input} --to python --output-dir=codes/scripts/ > {log.stdout} 2> {log.stderr}"

checkpoint list_solvers:
    output:
        "results/{solversuite}/solvers.txt"
    conda:
       "benchmark_{solversuite}"
    log:
        "results/{solversuite}/solvers.log"
    shell:
        "FIPY_SOLVERS={wildcards.solversuite} python codes/scripts/solvers.py > {output} 2> {log}"

checkpoint list_preconditioners:
    output:
        "results/{solversuite}/preconditioners.txt"
    conda:
       "benchmark_{solversuite}"
    log:
        "results/{solversuite}/preconditioners.log"
    shell:
        "FIPY_SOLVERS={wildcards.solversuite} python codes/scripts/preconditioners.py > {output} 2> {log}"

checkpoint thumbprint:
    output:
        thumb=temp("thumbprint-{solversuite}.txt")
    log:
        "thumbprint~{solversuite}.log"
    run:
        with open(output[0], "w") as f:
            f.write(get_thumbprint())

# checkpoint params:
#     output:
#         "results/{path}/{solversuite}/params.csv"
#     input:
#         "results/{path}/{solversuite}/preconditioners.txt",
#         "results/{path}/{solversuite}/solvers.txt",
#     run:
#         s = checkpoints.solvers
#         solve_file = s.get(path=wildcards.path,
#                            solversuite=wildcards.solversuite).output[0]
#         with open(solve_file, 'r') as f:
#             solvers = f.read().split()
# 
#         p = checkpoints.preconditioners
#         precon_file = p.get(path=wildcards.path,
#                             solversuite=wildcards.solversuite).output[0]
#         with open(p.get(path=wildcards.path,
#                         solversuite=wildcards.solversuite).output[0], 'r') as f:
#             preconditioners = f.read().split()
# 
#         df = pd.DataFrame(data=list(product(solvers, preconditioners, SIZES)),
#                           columns=["solver", "preconditioner", "size"])
# 
#         df.to_csv(output[0], index=False)

# rule all_suites:
#     output:
#         "results/benchmark~{benchmark}/all_suites.csv"
#     input:
#         get_suites
#     log:
#         "results/benchmark~{benchmark}/all_suites.log"
#     shell:
#         concat_csv(input, output[0], log)

rule all_solvers:
    output:
        "results/{path}/suite~{solversuite}/all_solvers.csv"
    input:
        "solvers~{solversuite}.txt",
        "preconditioners~{solversuite}.txt",
        get_solvers
    log:
        "results/{path}/suite~{solversuite}/all_solvers.log"
    run:
        concat_csv(input, output[0], log)

rule all_preconditioners:
    output:
        "results/{path}/suite~{solversuite}/solver~{solver}/all_preconditioners.csv"
    input:
        "preconditioners~{groupid}~{solversuite}.txt",
        get_preconditioners
    log:
        "results/{path}/suite~{solversuite}/solver~{solver}/all_preconditioners.log"
    run:
        concat_csv(input, output[0], log)

rule all_sizes:
    output:
        "results/{path}/all_sizes.csv"
    input:
        get_sizes
    log:
        "results/{path}/all_sizes.log"
    run:
        concat_csv(input, output[0], log)

rule all_hostnames:
    output:
        "results/{path}/all_hostnames.csv"
    input:
        get_hostnames
    log:
        "results/{path}/all_hostnames.log"
    run:
        concat_csv(input, output[0], log[0])

rule all_selfversions:
    output:
        "results/{path}/all_selfversions.csv"
    input:
        get_selfversions
    log:
        "results/{path}/all_selfversions.log"
    run:
        concat_csv(input, output[0], log)

rule all_fipyversions:
    output:
        "results/{path}/all_fipyversions.csv"
    input:
        get_fipyversions
    log:
        "results/{path}/all_fipyversions.log"
    run:
        concat_csv(input, output[0], log)

rule extract_times:
    output:
        csv="{path}/solver.csv"
    input:
        "{path}/solver.log"
    conda:
        "benchmark_analysis"
    log:
        "{path}/extract_times.log"
    shell:
        "touch {output.csv} 2> {log}"
#     notebook:
#         "codes/notebooks/extract.py.ipynb"

# rule extract_times:
#     output:
#         csv="results/{path}/suite~{solversuite}/solver~{solver}/preconditioner~{preconditioner}/size~{size}/solver.csv"
#     input:
#         "results/{path}/suite~{solversuite}/solver~{solver}/preconditioner~{preconditioner}/size~{size}/solver.log"
#     conda:
#         "benchmark_analysis"
#     log:
#         "results/{path}/suite~{solversuite}/solver~{solver}/preconditioner~{preconditioner}/size~{size}/solver.log"
#     shell:
#         "touch {output.csv} 2> {log}"
# #     notebook:
# #         "codes/notebooks/extract.py.ipynb"

# results/{script}/{platform}_{fipyversion}/{suite}/{solver}/{preconditioner}/{size}

# results/{script}/{suite}/{solver}/{preconditioner}/{size}/{platform}/{version}/{fipyversion}

rule solve:
    output:
        "results/benchmark~{benchmark}/suite~{solversuite}/solver~{solver}/"
        "preconditioner~{preconditioner}/size~{size}/hostname~{hostname}/"
        "self~{version}/fipy~{fipyversion}/solver.log"
    input:
        benchmark="codes/scripts/{benchmark}.py"
    params:
        output=lambda w, output: os.path.dirname(output[0])
    conda:
        "benchmark_{solversuite}"
    log:
        "results/benchmark~{benchmark}/suite~{solversuite}/"
            "solver~{solver}/preconditioner~{preconditioner}/size~{size}/"
            "hostname~{hostname}/self~{version}/fipy~{fipyversion}/solver.stderr"
    shell:
        "FIPY_SOLVERS={wildcards.solversuite} python {input.benchmark}"
        " --solver={wildcards.solver}"
        " --preconditioner={wildcards.preconditioner}"
        " --numberOfElements={wildcards.size}"
        " --output={params.output}"
        " 2> {log}"

rule aggregate_param_sweeps:
    output:
        "results/permutations.json"
    input:
        expand("results/{solversuite}/permutations.json", solversuite=SUITES)
    log:
        "results/permutations.log"
    run:
        concat_json(input, output[0], log[0])

checkpoint add_param_sweep:
    output:
        "results/{solversuite}/permutations.json"
    input:
        "results/{solversuite}/preconditioners.txt",
        "results/{solversuite}/solvers.txt",
    run:
        solvers = get_checkpoint_list(check=checkpoints.list_solvers,
                                      solversuite=wildcards.solversuite)
        preconditioners = get_checkpoint_list(check=checkpoints.list_preconditioners,
                                              solversuite=wildcards.solversuite)

        df = pd.DataFrame(data=list(product(BENCHMARKS, solvers, preconditioners, SIZES)),
                          columns=["benchmark", "solver", "preconditioner", "size"])

        df["uuid"] = [str(uuid.uuid4()) for item in df.iterrows()]
        df = df.set_index("uuid")

        df["suite"] = wildcards.solversuite
        df["hostname"] = platform.node()
        df["version"] = git_version(path=".")
        df["fipy_version"] = git_version(path=FIPY_PATH)

        df.to_json(output[0])

# rule all_config:
#     output:
#     input:
#         expand("results/{id}/solver.log",
#                id=PERMUTATIONS.index)

rule solve_config:
    output:
        "results/{id}/solver.log"
    input:
        config="results/{id}/config.json",
        benchmark=get_benchmark
    params:
        config=lambda w, input: read_config(input.config),
        output=lambda w, output: os.path.dirname(output[0])
    conda:
        get_conda_environment
    log:
        "results/{id}/solver.stderr"
    shell:
        "FIPY_SOLVERS={params.config[suite]}"
        " python {input.benchmark}"
        " --solver={params.config[solver]}"
        " --preconditioner={params.config[preconditioner]}"
        " --numberOfElements={params.config[size]}"
        " --output={params.output}"
        " 2> {log}"

rule make_config:
    output:
        "results/{id}/config.json"
    input:
        "results/permutations.json"
    run:
        df = pd.read_json(input[0])
        df.loc[wildcards.id].to_json(output[0])

rule plot:
    output:
        "results/{path}/{solversuite}/all.png"
    input:
        "results/{path}/{solversuite}/params.csv",
        get_params
